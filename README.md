# Electiva II - Deep Learning

**Tecnológico de Antioquia - Ingeniería en Software**

Repositorio del curso Electiva II - Deep Learning. Contiene las guías de trabajo práctico en formato Jupyter Notebook, diseñadas para ejecutarse en Google Colab.

## Instrucciones para estudiantes

### 1. Hacer Fork del repositorio
1. Haz clic en el botón **Fork** en la esquina superior derecha de este repositorio.
2. Esto creará una copia del repositorio en tu cuenta de GitHub.

### 2. Trabajar en Google Colab
1. Abre cada guía directamente en Google Colab desde tu fork.
2. Para abrir un notebook: ve a [Google Colab](https://colab.research.google.com/), selecciona **GitHub**, ingresa la URL de tu fork y selecciona la guía correspondiente.
3. Trabaja en el notebook siguiendo las instrucciones. Las secciones marcadas con ✍️ requieren tu respuesta escrita.

### 3. Guardar tu trabajo
1. Desde Colab: **Archivo → Guardar una copia en GitHub**.
2. Selecciona tu fork y haz commit directamente desde Colab.

### 4. Entregar
1. Copia el enlace directo al notebook en tu repositorio de GitHub.
2. Pégalo en el formulario de Google Forms proporcionado por el profesor.

## Estructura del repositorio

```
guias/          → Notebooks de las guías de trabajo (Google Colab)
datasets/       → Instrucciones sobre los datasets utilizados
recursos/       → Material complementario
```

## Guías

| # | Guía | Temas principales |
|---|------|-------------------|
| 01 | Fundamentos de DL: El Perceptrón | Perceptrón, neurona artificial, funciones de activación |
| 02 | Redes Neuronales con Keras | Redes multicapa, backpropagation, API de Keras |
| 03 | Optimización y Regularización | SGD, Adam, dropout, batch normalization, early stopping |
| 04 | DNN en Problemas Reales | Datos tabulares, callbacks, guardado de modelos |
| 05 | Redes Convolucionales (CNN) | Convoluciones, filtros, pooling, feature maps |
| 06 | CNN Avanzado: Transfer Learning | Data augmentation, VGG16, ResNet, fine-tuning |
| 07 | Redes Recurrentes (RNN y LSTM) | Secuencias, RNN, LSTM, GRU, series temporales |
| 08 | Transición a PyTorch | Tensores, autograd, nn.Module, DataLoader |
| 09 | PLN Fundamentos con NLTK | Tokenización, stemming, lematización, TF-IDF |
| 10 | Word Embeddings | Word2Vec, CBOW, Skip-gram, fastText, t-SNE |
| 11 | Clasificación de Texto con Transformers | Arquitectura Transformer, BETO, Hugging Face |
| 12 | Análisis de Sentimiento | Datos desbalanceados, F1, atención, interpretabilidad |
| 13 | Generación de Texto y NER | Modelos generativos, NER, temperature, top_k |
| 14 | Ética en IA | Sesgos algorítmicos, fairness, responsabilidad |

## Requisitos
- Cuenta de Google (para Google Colab)
- Cuenta de GitHub
- Navegador web actualizado
